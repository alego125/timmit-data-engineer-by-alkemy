# üìö Unidad 5 - Logueo de eventos en airflow 
----
> Toda esta pr√°ctica esta realizada en airflow mediante docker por medio del framework [astronomer](https://docs.astronomer.io/astro/cli/overview)

El dag generado ac√° lo que hace es extraer informaci√≥n de un archivo csv y generar un archivo xlsx de excel a partir de estos, estos se guardan en

```
include > archivos_temp
```

Adem√°s los logs son generados por un handler personalizado mediante el m√≥dulo creado logs.py y estos son mostrados en consola y genera sus respectivos archivos en la carpeta

```
include > logs
```

### üìùGuia
----
Utilizando los conceptos aprendidos en el m√≥dulo 5 - Loguear
Eventos en Airflow, resolver el siguiente ejercicio.

En el siguiente [link](https://drive.google.com/file/d/1-phtw_Q_2AFQVqh9U66-Etcg-ttQXzn7/view) se encuentra un DAG que realiza una consulta a
una [URL](http://winterolympicsmedals.com/medals.csv) y descarga un dataset de medallas ol√≠mpicas. Luego contabiliza el top ten de pa√≠ses con m√°s medallas y guarda los
resultados en un archivo en formato Excel.

Para utilizar este DAG, se deber√° descargar y copiar en la carpeta
DAGs de Airflow.

A partir del DAG propuesto, completar las partes comentadas, a fin de
agregar un logger personalizado que realice las siguientes tareas:

1) Indicarnos si la descarga del dataset se y procesamiento se realiz√≥
correctamente
2) Indicarnos si la tarea anterior fue fallida.
3) Mostrar el logging por consola y tambi√©n guardarlo en un archivo.

### üíªSetup
----
>Cabe aclarar que primero que nada al estar trabajando con atronomer el cual es un framework para airflow debemos instalarlo y este proceso puede variar seg√∫n el sistema operativo que tengamos para este paso hay que seguir las instrucciones oficiales de la p√°gina de [atronomer](https://docs.astronomer.io/astro/cli/install-cli)

**Instalaci√≥n en Windows**

1) Descargar el archivo astro.exe
2) Crear carpeta en el disco C:/astro dentro de esta llevar el .exe
3) Crear entrada al path de variables de entorno tanto del usuario com odel sistema colocar en el path la ruta C:/astro/astro.exe

Una vez instalado astronomer lo que se procede a hacer es la inicializaci√≥n del proyecto, en el directorio asignado mediante l√≠nea de comando escribir

~~~
astro dev init
~~~

Con esto inicializamos el proyecto cre√°ndose toda la estructura necesaria para correrlo.

Seguidamente se debe correr el arranque de los contenedores docker para poder acceder al proyecto creado para esto ejecutamos el comando

~~~
astro dev start
~~~

De esta manera se descargan los contenedores (en caso de no tenerlos descargados) y seguidamente se inicializan mediante docker compose. Todo esto se hace autom√°ticamente por detr√°s de astronomer.

Una vez lanzado el proyecto podremos tener acceso, ya que autom√°ticamente al terminar de ejecutarse lanza una ventana del navegador con la direcci√≥n para iniciar sesi√≥n. 

```
Usuario -> admin

Contrase√±a -> admin
```

**Ingresar al bash de astro**

Para esto debemos ingresar el siguiente comando

~~~
astro dev bash
~~~

Con esto entramos al bash de atronomer donde podremos colocar los comandos de airflow como por ejemplo <code>airflow config</code> el cual es el comando para ver la configuraci√≥n de airflow. O tambi√©n podremos acceder al archivo directamente navegando entre ello hasta el archivo config de airflow.

**Resetear el servicio**

~~~
astro dev restart
~~~

**Detener el servicio**

~~~
astro dev stop
~~~

##### üßµ Dependencias 
----

‚ö† __En los casos donde queramos instalar nuevas dependencias, en astronomer deberemos hacerlo directamente en el archivo requirements.txt y realizar un reset del servicio, ya que autom√°ticamente al reiniciar escanea los requerimientos nuevamente y en caso de encontrar uno nuevo lo instala en el proceso de inicio.__ ‚ö†

### ‚ö°Setup y manejo de dags 
----

* Si hacemos clic sobre el dag que queremos utilizar en la pantalla principal de airlflow nos abrir√° el dag, dentro podremos ver por ejemplo el graph que es como se ejecuta o el diagrama de ejecuci√≥n de dag que tenemos este se vera como la siguiente imagen:

![image](https://user-images.githubusercontent.com/76167482/201475802-d9dbe0b0-16bf-4c35-ad15-8928bd68ff18.png)

* Dentro de table o tree tendremos la secuencia de ejecuciones que se han realizado con sus respectivos colores los cuales nos indican el estado de cada ejecuci√≥n en la l√≠nea temporal

![image](https://user-images.githubusercontent.com/76167482/201475838-d27a6bdb-2ae2-4935-a70e-2b1802c390df.png)

* Para ejecutar el dag simplemente se debe hacer clic sobre el bot√≥n de play en la parte superior derecha

##### üî∞ Logs en dags y visualizacion 

* Si quisi√©ramos ver los logs hacemos clic en el √∫ltimo cuadrado verde de la tarea
del ejemplo ‚Äúdrop_table‚Äù, se abrir√° el siguiente men√∫

![image](https://user-images.githubusercontent.com/76167482/201475873-8a6cc45a-b87a-4cc3-b9ca-38206c777b8f.png)

* Si hacemos clic en el bot√≥n ‚ÄúLog‚Äù, accederemos a los logs de esa
tarea, que se encuentran detallados en el panel ‚ÄúLog by attempts‚Äù

![image](https://user-images.githubusercontent.com/76167482/201475889-9d764103-e855-4382-a622-e8ba920f0b9b.png)

En el recuadro n¬∞ 1 podemos ver que se gener√≥ el siguiente archivo
log:

>BI_Crear_tabla_acrom_licencias/drop_table/2022-08-04T15:19:40.
>663716+00:00/1.log

Podemos notar que la estructura de ese nombre se corresponde con
la definida para la variable **log_filename_template** en el archivo
**airflow.cfg.**

Recordando la definici√≥n de la variable:

**log_filename_template = {{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{
try_number }}.log**

Podemos comprobar:

* ti.dag_id = BI_Crear_tabla_acrom_licencias
* ti.task_id = create_table
* ts: 2022-08-04T15:19:40.663716+00:00
* try_number: 1

En el recuadro n¬∞ 2 podemos ver la l√≠nea de log que se escribi√≥ en el
archivo log que vimos en el recuadro n¬∞ 1.

>[2022-08-04, 15:19:42 UTC] {taskinstance.py:1037} INFO -
>Dependencies all met for TaskInstance: BI_Crear_tabla_acrom_licencias.drop_table
>manual__2022-08-04T15:19:40.663716+00:00 [queued]

El formato de esa l√≠nea es el que se especifica en la variable
log_format del archivo airflow.cfg.

Recordando la definici√≥n de la variable:

**log_format = [%%(asctime)s] {%%(filename)s:%%(lineno)d}
%%(levelname)s - %%(message)s**

Podemos comprobar:
* [%%(asctime)s]: [2022-08-04, 15:19:42 UTC]
* filename: taskinstance.py
* lineno: 1037
* levelname: INFO
‚óè message: Dependencies all met for <TaskInstance:

>BI_Crear_tabla_acrom_licencias.drop_table
>manual__2022-08-04T15:19:40.663716+00:00 [queued]

### ‚Ñπ Para informacion extra sobre dags y airflow visitar [Pagina oficial de airflow](https://airflow.apache.org/docs/apache-airflow/stable/index.html)


